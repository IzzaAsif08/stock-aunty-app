import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

def preprocess_data(df):
    """
    Preprocess the dataframe by:
    - Dropping rows with missing values.
    - Selecting only numerical columns.
    - Standardizing the data.
    """
    # Drop rows with missing values
    df = df.dropna()

    # Select only numerical columns
    df = df.select_dtypes(include=['number'])

    # Normalize numerical data using StandardScaler
    scaler = StandardScaler()
    df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)
    
    return df_scaled

def feature_engineer(df):
    """
    Feature engineering:
    - Creates a new feature 'Return' based on percentage change of 'Close' column.
    - Drops missing values after calculation.
    """
    if 'Close' not in df.columns:
        raise ValueError("The 'Close' column is missing from the data.")
    
    # Create the 'Return' column as the percentage change of 'Close'
    df['Return'] = df['Close'].pct_change()
    
    # Drop any rows with NaN values generated by pct_change
    df.dropna(inplace=True)
    
    return df

def train_test(df):
    """
    Split the data into training and testing sets.
    """
    if 'Return' not in df.columns:
        raise ValueError("Data must contain a 'Return' column for target variable.")

    # Split the features (X) and target (y)
    X = df.drop('Return', axis=1)
    y = (df['Return'] > 0).astype(int)  # Create binary target (1 if Return > 0, else 0)

    # Split the data into training and test sets (80% train, 20% test)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    return X_train, X_test, y_train, y_test

def train_logistic_regression(X_train, y_train):
    """
    Train a logistic regression model with the training data.
    """
    model = LogisticRegression(max_iter=1000)  # Allow for more iterations if needed
    model.fit(X_train, y_train)  # Train the model
    return model

def train_kmeans(df, n_clusters=3):
    """
    Train a KMeans clustering model on the dataset.
    """
    # Ensure data has the right structure
    if df.empty or len(df.columns) == 0:
        raise ValueError("Dataframe is empty or lacks columns for clustering.")

    if 'Return' not in df.columns:
        raise ValueError("Data must contain a 'Return' column for clustering.")
    
    # Normalize the data before applying KMeans
    scaler = StandardScaler()
    df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)

    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    kmeans.fit(df_scaled)  # Train the model
    return kmeans
